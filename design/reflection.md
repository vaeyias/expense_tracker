# Project Reflection

## Overall Experience
Using agentic AI tools like **Copilot**, **Cursor**, and **Gemini LLM** made implementing my website much easier, though each tool came with its own challenges. These tools definitely helped me accelerate development and handle repetitive tasks but also required careful review and management.
## How Using Agentic AI Tools Helped
- AI tools made implementing more complex features like formulating all my syncs a lot easier. Even if it didn't give me working code, it gave me a nice foundation to build off of.
- Could implement tedious/repetitive code quickly, such as applying a styling change to components across multiple files.
- AI tools enabled me to implement complicated features I probably would have struggled with/or taken a lot of time to implement. For example, implementing a confetti animation after a user records a payment.

## Difficulties with Using AI Tools
- Broad prompts sometimes changed unrelated files or styling, which made tracking changes difficult.
- I overrelied on AI tools to implement some features without fully understanding what the code does. This caused a lot of difficulties trying to debug code.
- I used Copilot for the builk of my frontend implementation, but I found that it rarely gave me working code or the styling I wanted. So, this required a lot of manual coding to correct.

## Comparison of Different AI Tools
- I found Cursor to be significantly more effective than Copilot.
- For frontend code, using Copilot and Cursor were definitely more effective than trying to use Context tool because Copilot/Cursor could read any file in my workspace to implement the frontend. The frontend requires a comprehensive understanding of how the concepts work together.
- For backend code, using Context Gemini LLM was more effective because to implement Concepts, you only need to know about the concept you want to implement. So manually giving the LLM what context it needs to implement the code was effective for this.


## Mistakes/Lessons Learned
- I sometimes relied too much on AI-generated code without fully reviewing or understanding it. This would cause issues that would make it hard to debug in the future. For example, sometimes Cursor changed many of my files and it felt tedious to look through every change. However, I realized that Cursor changed a file I didn't want to be modified.
  - *Lesson:* Always inspect AI-generated code before integration.
- Large or vague prompts caused unintended modifications to multiple files.
  - *Lesson:* Use smaller, more targeted prompts to control changes.
- The **Context tool** was helpful for tracking how my implementation evolved over time.


## Skills Gained and Areas to Improve
- **Gained:**
  - Experience balancing AI coding support with manual implementation.
  - Stronger understanding of web development logic through trying to understand code generated by AI tools.
  -  Learn how to use Context tool! This will be helpful for future coding projects.
  - Foundational understanding of core backend principles, API design, and sync implementation.

- **Need to Improve:**
  - Deeper comprehension of AI-generated frontend code. Most of the styling on my frontend was generated and I made smaller changes like coloring/centering of components so I don't fully understand how some of my style code works.
  - More strategic prompting and version control when using free AI tools.


## Conclusions on LLM use in Software Dvelopment
- LLMs are an extremely powerful tool for coding, automating repetitive tasks, and generating code patterns.
- However, human understanding and oversight are essential or debugging and long-term maintainability.
- Version control is super important in general, but especially when using LLMs to implement/modify code to ensure there were no unintended affects of the generated code that we didn't catch immediately.
